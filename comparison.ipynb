{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "p9ma0Gra5R03",
        "outputId": "43230ada-b90a-4b5b-a9d3-59ec71837d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ä¸­æ–‡å­—å‹æº–å‚™å®Œæˆ\n",
            "âœ… OpenAI Client åˆå§‹åŒ–å®Œæˆ\n",
            "============================================================\n",
            "ã€NLP æŠ€è¡“å°æ¯”åˆ†æå ±å‘Šã€‘\n",
            "============================================================\n",
            "âœ… åˆ†é¡çµæœå·²å„²å­˜ (4ç­†è³‡æ–™): results/classification_results.csv\n",
            "\n",
            "[ç”Ÿæˆ TF-IDF ç›¸ä¼¼åº¦çŸ©é™£åœ–...]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 25991 (\\N{CJK UNIFIED IDEOGRAPH-6587}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.12/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 20214 (\\N{CJK UNIFIED IDEOGRAPH-4EF6}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… åœ–ç‰‡å„²å­˜æˆåŠŸ : results/tfidf_similarity_matrix.png\n",
            "\n",
            "[C-1 é‡åŒ–æ¯”è¼ƒè¡¨æ ¼]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     è©•ä¼°é¢å‘   è©•ä¼°æŒ‡æ¨™ TF-IDF (å‚³çµ±) GPT-4o (AI)\n",
              "0   ç›¸ä¼¼åº¦è¨ˆç®—                               \n",
              "1            æº–ç¢ºç‡     ä½ (åƒ…å­—é¢)     é«˜ (å«èªæ„)\n",
              "2           è™•ç†æ™‚é–“     0.0055ç§’     0.6062ç§’\n",
              "3             æˆæœ¬          $0     Tokenè¨ˆè²»\n",
              "4    æ–‡æœ¬åˆ†é¡                               \n",
              "5            æº–ç¢ºç‡         50%        100%\n",
              "6           è™•ç†æ™‚é–“     0.0003ç§’     0.5522ç§’\n",
              "7           æ”¯æ´é¡åˆ¥          æœ‰é™          ç„¡é™\n",
              "8    è‡ªå‹•æ‘˜è¦                               \n",
              "9          è³‡è¨Šä¿ç•™åº¦      ä¸­ (æŠ½å–)      é«˜ (ç”Ÿæˆ)\n",
              "10         èªå¥é€šé †åº¦      ä½ (æ‹¼æ¥)      é«˜ (è‡ªç„¶)\n",
              "11          é•·åº¦æ§åˆ¶          å›°é›£          å®¹æ˜“"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-611253a0-5e01-450a-ab77-a7737abc688e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>è©•ä¼°é¢å‘</th>\n",
              "      <th>è©•ä¼°æŒ‡æ¨™</th>\n",
              "      <th>TF-IDF (å‚³çµ±)</th>\n",
              "      <th>GPT-4o (AI)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ç›¸ä¼¼åº¦è¨ˆç®—</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>æº–ç¢ºç‡</td>\n",
              "      <td>ä½ (åƒ…å­—é¢)</td>\n",
              "      <td>é«˜ (å«èªæ„)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>è™•ç†æ™‚é–“</td>\n",
              "      <td>0.0055ç§’</td>\n",
              "      <td>0.6062ç§’</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>æˆæœ¬</td>\n",
              "      <td>$0</td>\n",
              "      <td>Tokenè¨ˆè²»</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>æ–‡æœ¬åˆ†é¡</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>æº–ç¢ºç‡</td>\n",
              "      <td>50%</td>\n",
              "      <td>100%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td>è™•ç†æ™‚é–“</td>\n",
              "      <td>0.0003ç§’</td>\n",
              "      <td>0.5522ç§’</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>æ”¯æ´é¡åˆ¥</td>\n",
              "      <td>æœ‰é™</td>\n",
              "      <td>ç„¡é™</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>è‡ªå‹•æ‘˜è¦</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>è³‡è¨Šä¿ç•™åº¦</td>\n",
              "      <td>ä¸­ (æŠ½å–)</td>\n",
              "      <td>é«˜ (ç”Ÿæˆ)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td></td>\n",
              "      <td>èªå¥é€šé †åº¦</td>\n",
              "      <td>ä½ (æ‹¼æ¥)</td>\n",
              "      <td>é«˜ (è‡ªç„¶)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td></td>\n",
              "      <td>é•·åº¦æ§åˆ¶</td>\n",
              "      <td>å›°é›£</td>\n",
              "      <td>å®¹æ˜“</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-611253a0-5e01-450a-ab77-a7737abc688e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-611253a0-5e01-450a-ab77-a7737abc688e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-611253a0-5e01-450a-ab77-a7737abc688e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa843238-ec19-45a5-a829-7a52946fa485\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa843238-ec19-45a5-a829-7a52946fa485')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa843238-ec19-45a5-a829-7a52946fa485 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"analyzer\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"\\u8a55\\u4f30\\u9762\\u5411\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\",\n          \"\\u81ea\\u52d5\\u6458\\u8981\",\n          \"\\u76f8\\u4f3c\\u5ea6\\u8a08\\u7b97\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u8a55\\u4f30\\u6307\\u6a19\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\\u6e96\\u78ba\\u7387\",\n          \"\\u8cc7\\u8a0a\\u4fdd\\u7559\\u5ea6\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TF-IDF (\\u50b3\\u7d71)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u4f4e (\\u62fc\\u63a5)\",\n          \"\\u4f4e (\\u50c5\\u5b57\\u9762)\",\n          \"0.0003\\u79d2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPT-4o (AI)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u9ad8 (\\u81ea\\u7136)\",\n          \"\\u9ad8 (\\u542b\\u8a9e\\u610f)\",\n          \"0.5522\\u79d2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼\n",
            "çµæœæª”æ¡ˆä½ç½®: results/\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import jieba\n",
        "import time\n",
        "import math\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# ==================== 0. å®‰è£èˆ‡è¨­å®šä¸­æ–‡å­—å‹ ====================\n",
        "if not os.path.exists('SimHei.ttf'):\n",
        "    print(\"æ­£åœ¨ä¸‹è¼‰ä¸­æ–‡å­—å‹ (SimHei)...\")\n",
        "    os.system('wget -q https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf')\n",
        "\n",
        "font_path = 'SimHei.ttf'\n",
        "my_font = fm.FontProperties(fname=font_path)\n",
        "print(\"âœ… ä¸­æ–‡å­—å‹æº–å‚™å®Œæˆ\")\n",
        "\n",
        "# ==================== 1. ç’°å¢ƒèˆ‡ AI å‡½å¼è¨­ç½® (æ•´åˆ modern_methods.ipynb) ====================\n",
        "\n",
        "# 1. API Client åˆå§‹åŒ–\n",
        "# å¾ Colab Secrets è®€å–é‡‘é‘°ï¼Œä¸¦åˆå§‹åŒ– OpenAI Client\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI()\n",
        "print(\"âœ… OpenAI Client åˆå§‹åŒ–å®Œæˆ\")\n",
        "\n",
        "# Part A æ¸¬è©¦æ•¸æ“š (ä¾†è‡ªåŸå§‹ç¨‹å¼ç¢¼)\n",
        "documents_for_A1 = [\n",
        "    \"äººå·¥æ™ºæ…§æ­£åœ¨æ”¹è®Šä¸–ç•Œï¼Œæ©Ÿå™¨å­¸ç¿’æ˜¯å…¶æ ¸å¿ƒæŠ€è¡“\",\n",
        "    \"æ·±åº¦å­¸ç¿’æ¨å‹•äº†äººå·¥æ™ºæ…§çš„ç™¼å±•ï¼Œç‰¹åˆ¥æ˜¯åœ¨åœ–åƒè­˜åˆ¥é ˜åŸŸ\",\n",
        "    \"ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œé©åˆå‡ºå»é‹å‹•\",\n",
        "    \"æ©Ÿå™¨å­¸ç¿’å’Œæ·±åº¦å­¸ç¿’éƒ½æ˜¯äººå·¥æ™ºæ…§çš„é‡è¦åˆ†æ”¯\",\n",
        "    \"é‹å‹•æœ‰ç›Šå¥åº·ï¼Œæ¯å¤©éƒ½æ‡‰è©²ä¿æŒé‹å‹•ç¿’æ…£\",\n",
        "]\n",
        "\n",
        "# 2. çœŸå¯¦ AI å‡½å¼å®šç¾© (ä¾†è‡ª modern_methods.ipynb)\n",
        "# B-1: èªæ„ç›¸ä¼¼åº¦è¨ˆç®—\n",
        "def ai_similarity(text1, text2, api_key=None):\n",
        "    prompt = f\"\"\"\n",
        "è«‹è©•ä¼°ä»¥ä¸‹å…©æ®µæ–‡å­—çš„èªæ„ç›¸ä¼¼åº¦ã€‚\n",
        "æ–‡å­—1: {text1}\n",
        "æ–‡å­—2: {text2}\n",
        "è«‹åªå›ç­”ä¸€å€‹0-100çš„æ•¸å­—ï¼Œä»£è¡¨ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”ã€‚\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ä½ æ˜¯ç¹é«”ä¸­æ–‡èªæ„åˆ†æå°ˆå®¶ï¼Œåªèƒ½å›ç­”æ•¸å­—ã€‚\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0,\n",
        "            max_tokens=10\n",
        "        )\n",
        "        result_text = response.choices[0].message.content.strip()\n",
        "        match = re.search(r'\\d+', result_text)\n",
        "        if match:\n",
        "            score = int(match.group())\n",
        "            return max(0, min(100, score))\n",
        "        return 0\n",
        "    except Exception as e:\n",
        "        # print(f\"API å‘¼å«ç™¼ç”ŸéŒ¯èª¤: {e}\") # åŸ·è¡Œæ™‚å¯å–æ¶ˆè¨»è§£æŸ¥çœ‹éŒ¯èª¤\n",
        "        return 0\n",
        "\n",
        "# B-2: AI æ–‡æœ¬åˆ†é¡\n",
        "def ai_classify(text, api_key=None):\n",
        "    prompt = f\"\"\"\n",
        "è«‹åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿèˆ‡ä¸»é¡Œã€‚\n",
        "æ–‡æœ¬å…§å®¹: \"{text}\"\n",
        "è«‹å›å‚³ä¸€å€‹ JSON ç‰©ä»¶ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š\n",
        "1. \"sentiment\": åˆ¤æ–·æƒ…æ„Ÿï¼Œåªèƒ½æ˜¯ \"æ­£é¢\"ã€\"è² é¢\" æˆ– \"ä¸­æ€§\"ã€‚\n",
        "2. \"topic\": åˆ¤æ–·ä¸»é¡Œé¡åˆ¥ (ä¾‹å¦‚ï¼šç¾é£Ÿã€ç§‘æŠ€ã€é‹å‹•ã€å¨›æ¨‚ã€æ—…éŠã€ç”Ÿæ´»...ç­‰ï¼Œè«‹ä¾æ“šå…§å®¹è‡ªå‹•åˆ¤æ–·æœ€é©åˆçš„è©)ã€‚\n",
        "3. \"confidence\": ä¿¡å¿ƒåˆ†æ•¸ (0.0 åˆ° 1.0 ä¹‹é–“)ã€‚\n",
        "åªå›å‚³ JSON å­—ä¸²ï¼Œä¸è¦æœ‰å…¶ä»–èªªæ˜ã€‚\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„æ–‡æœ¬åˆ†æ APIï¼Œåªå›å‚³ JSON æ ¼å¼ã€‚\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        result_text = response.choices[0].message.content.strip()\n",
        "        if result_text.startswith(\"```json\"):\n",
        "            result_text = result_text.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        data = json.loads(result_text)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        # print(f\"AI åˆ†é¡ç™¼ç”ŸéŒ¯èª¤: {e}\") # åŸ·è¡Œæ™‚å¯å–æ¶ˆè¨»è§£æŸ¥çœ‹éŒ¯èª¤\n",
        "        return {\"sentiment\": \"æœªçŸ¥\", \"topic\": \"æœªçŸ¥\", \"confidence\": 0.0}\n",
        "\n",
        "# B-3: AI è‡ªå‹•æ‘˜è¦\n",
        "def ai_summarize(text, ratio=0.3, api_key=None):\n",
        "    target_percent = int(ratio * 100)\n",
        "    prompt = f\"\"\"\n",
        "è«‹æ‰®æ¼”ä¸€ä½å°ˆæ¥­ç·¨è¼¯ï¼Œå°‡ä»¥ä¸‹æ–‡ç« é€²è¡Œæ‘˜è¦ã€‚\n",
        "è¦æ±‚ï¼š\n",
        "1. ä¿ç•™æ–‡ç« çš„æ ¸å¿ƒè³‡è¨Šèˆ‡é—œéµè«–é»ã€‚\n",
        "2. èªå¥å¿…é ˆé€šé †æµæš¢ã€‚\n",
        "3. æ‘˜è¦é•·åº¦å¤§ç´„æ§åˆ¶åœ¨åŸæ–‡çš„ {target_percent}% å·¦å³ã€‚\n",
        "æ–‡ç« å…§å®¹:\n",
        "{text}\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½ç²¾é€šç¹é«”ä¸­æ–‡çš„å°ˆæ¥­ç·¨è¼¯ã€‚\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        summary = response.choices[0].message.content.strip()\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        # print(f\"AI æ‘˜è¦ç™¼ç”ŸéŒ¯èª¤: {e}\") # åŸ·è¡Œæ™‚å¯å–æ¶ˆè¨»è§£æŸ¥çœ‹éŒ¯èª¤\n",
        "        return \"æ‘˜è¦ç”Ÿæˆå¤±æ•—\"\n",
        "\n",
        "# ==================== 2. å®šç¾© Part A å‚³çµ±æ–¹æ³•é¡åˆ¥ (ä¿®æ­£ RuleBasedClassifier) ====================\n",
        "\n",
        "class RuleBasedClassifier:\n",
        "    \"\"\"\n",
        "    ä¿®æ­£å¾Œçš„è¦å‰‡åˆ†é¡å™¨ï¼š\n",
        "    é‚è¼¯å®Œå…¨æ¯”ç…§ traditional_methods.ipynb çš„ TopicClassifier èˆ‡ RuleBasedSentimentClassifier\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # 1. ä¸»é¡Œé—œéµå­—\n",
        "        self.topic_keywords = {\n",
        "            'ç§‘æŠ€': ['AI', 'äººå·¥æ™ºæ…§', 'é›»è…¦', 'è»Ÿé«”', 'ç¨‹å¼', 'æ¼”ç®—æ³•'],\n",
        "            'é‹å‹•': ['é‹å‹•', 'å¥èº«', 'è·‘æ­¥', 'æ¸¸æ³³', 'çƒé¡', 'æ¯”è³½'],\n",
        "            'ç¾é£Ÿ': ['åƒ', 'é£Ÿç‰©', 'é¤å»³', 'ç¾å‘³', 'æ–™ç†', 'çƒ¹é£ª'],\n",
        "            'æ—…éŠ': ['æ—…è¡Œ', 'æ™¯é»', 'é£¯åº—', 'æ©Ÿç¥¨', 'è§€å…‰', 'åº¦å‡']\n",
        "        }\n",
        "\n",
        "        # 2. æƒ…æ„Ÿé—œéµå­—èˆ‡ç¨‹åº¦å‰¯è©\n",
        "        self.positive_words = ['å¥½', 'æ£’', 'å„ªç§€', 'å–œæ­¡', 'æ¨è–¦', 'æ»¿æ„', 'é–‹å¿ƒ', 'å€¼å¾—', 'ç²¾å½©', 'å®Œç¾']\n",
        "        self.negative_words = ['å·®', 'ç³Ÿ', 'å¤±æœ›', 'è¨å­', 'ä¸æ¨è–¦', 'æµªè²»', 'ç„¡èŠ', 'çˆ›', 'ç³Ÿç³•', 'å·®å‹']\n",
        "        self.negation_words = ['ä¸', 'æ²’', 'ç„¡', 'é', 'åˆ¥']\n",
        "\n",
        "        self.degree_words = {\n",
        "            'å¾ˆ': 1.5, 'éå¸¸': 2.0, 'è¶…': 2.0, 'å¤ª': 1.8, 'ç‰¹åˆ¥': 1.5,\n",
        "            'çœŸçš„': 1.3, 'çœŸ': 1.3, 'ååˆ†': 1.8, 'ç›¸ç•¶': 1.5\n",
        "        }\n",
        "\n",
        "    def classify(self, text):\n",
        "        # ========== Part 1: ä¸»é¡Œåˆ†é¡ (Topic) ==========\n",
        "        # é‚è¼¯ï¼šä½¿ç”¨ count() è¨ˆç®—å‡ºç¾æ¬¡æ•¸ï¼Œä¿¡å¿ƒåº¦ç‚º raw score (æ•´æ•¸)\n",
        "        topic_scores = {topic: 0 for topic in self.topic_keywords}\n",
        "\n",
        "        for topic, keywords in self.topic_keywords.items():\n",
        "            for kw in keywords:\n",
        "                # å·®ç•°é»ï¼šä½¿ç”¨ text.count(kw) è€Œé if kw in text\n",
        "                count = text.count(kw)\n",
        "                topic_scores[topic] += count\n",
        "\n",
        "        max_score = max(topic_scores.values())\n",
        "        if max_score == 0:\n",
        "            best_topic = \"æœªåˆ†é¡\"\n",
        "            topic_confidence = 0\n",
        "        else:\n",
        "            best_topic = max(topic_scores, key=topic_scores.get)\n",
        "            topic_confidence = max_score  # ç›´æ¥ä½¿ç”¨å¾—åˆ†ä½œç‚ºä¿¡å¿ƒåº¦\n",
        "\n",
        "        # ========== Part 2: æƒ…æ„Ÿåˆ†é¡ (Sentiment) ==========\n",
        "        # é‚è¼¯ï¼šåŠ å…¥ç¨‹åº¦å‰¯è©åŠ æ¬Šï¼Œä¿¡å¿ƒåº¦ç‚ºæ­£è² åˆ†æ•¸å·®å€¼\n",
        "        positive_count = 0\n",
        "        negative_count = 0\n",
        "\n",
        "        i = 0\n",
        "        while i < len(text):\n",
        "            # æª¢æŸ¥ç¨‹åº¦å‰¯è©\n",
        "            degree_multiplier = 1.0\n",
        "            for degree_word, weight in self.degree_words.items():\n",
        "                if text[i:i+len(degree_word)] == degree_word:\n",
        "                    degree_multiplier = weight\n",
        "                    i += len(degree_word)\n",
        "                    break\n",
        "\n",
        "            # æª¢æŸ¥å¦å®šè©\n",
        "            is_negated = False\n",
        "            for neg_word in self.negation_words:\n",
        "                if text[i:i+len(neg_word)] == neg_word:\n",
        "                    is_negated = True\n",
        "                    i += len(neg_word)\n",
        "                    break\n",
        "\n",
        "            # æª¢æŸ¥æ­£é¢è©\n",
        "            found = False\n",
        "            for pos_word in self.positive_words:\n",
        "                if text[i:i+len(pos_word)] == pos_word:\n",
        "                    if is_negated:\n",
        "                        negative_count += degree_multiplier\n",
        "                    else:\n",
        "                        positive_count += degree_multiplier\n",
        "                    i += len(pos_word)\n",
        "                    found = True\n",
        "                    break\n",
        "            if found: continue\n",
        "\n",
        "            # æª¢æŸ¥è² é¢è©\n",
        "            for neg_word in self.negative_words:\n",
        "                if text[i:i+len(neg_word)] == neg_word:\n",
        "                    if is_negated:\n",
        "                        positive_count += degree_multiplier\n",
        "                    else:\n",
        "                        negative_count += degree_multiplier\n",
        "                    i += len(neg_word)\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if not found:\n",
        "                i += 1\n",
        "\n",
        "        if positive_count > negative_count:\n",
        "            sentiment = 'æ­£é¢'\n",
        "        elif negative_count > positive_count:\n",
        "            sentiment = 'è² é¢'\n",
        "        else:\n",
        "            sentiment = 'ä¸­æ€§'\n",
        "\n",
        "        # é€™è£¡çš„ confidence å›å‚³çš„æ˜¯ã€Œä¸»é¡Œåˆ†é¡çš„ä¿¡å¿ƒåº¦ã€ï¼Œ\n",
        "        # å› ç‚ºæ¯”è¼ƒå ±å‘Šä¸»è¦æ˜¯åœ¨æ¯”è¼ƒä¸»é¡Œåˆ†é¡çš„æº–ç¢ºç‡ã€‚\n",
        "        return {\n",
        "            \"topic\": best_topic,\n",
        "            \"sentiment\": sentiment,\n",
        "            \"raw_score\": topic_confidence  # ä¾‹å¦‚ï¼š2 (ä»£è¡¨åŒ¹é…åˆ°2æ¬¡)\n",
        "        }\n",
        "\n",
        "# ä¿ç•™ StatisticalSummarizer å’Œ TFIDFSimilarity_For_Comparison çš„åŸå§‹å®šç¾©\n",
        "\n",
        "\n",
        "class StatisticalSummarizer:\n",
        "    # ... (ä¿ç•™ StatisticalSummarizer çš„åŸå§‹å®šç¾©)\n",
        "    def __init__(self):\n",
        "        # æ“´å……åœç”¨è©ä»¥æ”¹å–„æ•ˆæœ\n",
        "        self.stop_words = set(['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€å€‹', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'èªª', 'è¦', 'å»', 'ä½ ', 'é€™', 'é‚£', 'æœƒ', 'ç‚º', 'è‘—', 'ä¹‹', 'èˆ‡', 'åŠ', 'å…¶', 'æˆ–', 'ä½†', 'è€Œ'])\n",
        "\n",
        "    def sentence_score(self, sentence, word_freq, index=0, total_sentences=1):\n",
        "        # (ä¿ç•™ sentence_score å‡½å¼åŸå§‹é‚è¼¯)\n",
        "        if not sentence: return 0\n",
        "        score = sum(word_freq.get(w, 0) for w in sentence if w not in self.stop_words)\n",
        "        if index == 0: score *= 2.0\n",
        "        elif index == total_sentences - 1: score *= 1.5\n",
        "        if len(sentence) < 5: score *= 0.5 # é•·åº¦æ‡²ç½°\n",
        "        return score\n",
        "\n",
        "    def summarize(self, text, ratio=0.3):\n",
        "        # (ä¿ç•™ summarize å‡½å¼åŸå§‹é‚è¼¯)\n",
        "        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)\n",
        "        clean_sentences = []\n",
        "        for i in range(0, len(sentences)-1, 2):\n",
        "            if sentences[i].strip():\n",
        "                clean_sentences.append(sentences[i] + sentences[i+1])\n",
        "        if len(sentences) % 2 != 0 and sentences[-1].strip(): # è™•ç†æœ€å¾Œå¯èƒ½å‰©é¤˜çš„éƒ¨åˆ†\n",
        "             clean_sentences.append(sentences[-1])\n",
        "        if not clean_sentences: return \"\", []\n",
        "\n",
        "        all_content = \"\".join(clean_sentences)\n",
        "        # ç°¡å–®åˆ†è©ï¼šé€™è£¡ä»¥ã€Œå­—å…ƒã€ç‚ºå–®ä½ï¼Œéæ¿¾åœç”¨è©å’Œæ¨™é»\n",
        "        all_words = [c for c in all_content if c not in self.stop_words and c.strip() and c not in 'ã€‚ï¼ï¼Ÿï¼Œã€ï¼šï¼›ã€Œã€ã€ã€']\n",
        "        word_freq = Counter(all_words)\n",
        "        total_words = len(all_words)\n",
        "        word_freq_norm = {k: v/total_words for k, v in word_freq.items()}\n",
        "\n",
        "        sentence_scores = []\n",
        "        for i, sent in enumerate(clean_sentences):\n",
        "            score = self.sentence_score(sent, word_freq_norm, index=i, total_sentences=len(clean_sentences))\n",
        "            sentence_scores.append((i, sent, score))\n",
        "\n",
        "        num_sentences = max(1, int(len(clean_sentences) * ratio))\n",
        "        top_sentences = sorted(sentence_scores, key=lambda x: x[2], reverse=True)[:num_sentences]\n",
        "        top_sentences.sort(key=lambda x: x[0])\n",
        "        return \"\".join([item[1] for item in top_sentences]), sentence_scores\n",
        "\n",
        "\n",
        "class TFIDFSimilarity_For_Comparison:\n",
        "    def __init__(self):\n",
        "        # ç§»é™¤åŸæœ¬è¤‡é›œçš„ regexï¼Œæ”¹ç”¨é è¨­å€¼ (å› ç‚ºæˆ‘å€‘æœƒè‡ªå·±åŠ ç©ºç™½)\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.vocab = set()\n",
        "\n",
        "    def fit(self, documents):\n",
        "        # å…ˆç”¨ jieba æ–·è©ä¸¦åŠ ç©ºç™½\n",
        "        docs_cut = [\" \".join(jieba.lcut(doc)) for doc in documents]\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(docs_cut)\n",
        "\n",
        "    def get_similarity(self, text1, text2):\n",
        "        # å°è¼¸å…¥çš„å…©å€‹æ–‡æœ¬é€²è¡Œæ–·è©\n",
        "        t1_cut = \" \".join(jieba.lcut(text1))\n",
        "        t2_cut = \" \".join(jieba.lcut(text2))\n",
        "\n",
        "        # è¨ˆç®—ç›¸ä¼¼åº¦\n",
        "        matrix = self.vectorizer.fit_transform([t1_cut, t2_cut])\n",
        "        return cosine_similarity(matrix)[0][1]\n",
        "\n",
        "# ==================== 3. å®šç¾©æ¯”è¼ƒåˆ†æé¡åˆ¥ (ä¿ç•™åŸå§‹ç¨‹å¼ç¢¼) ====================\n",
        "\n",
        "class ComparisonAnalysis_With_Saving:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.trad_sim = TFIDFSimilarity_For_Comparison()\n",
        "        self.trad_clf = RuleBasedClassifier()\n",
        "        self.trad_sum = StatisticalSummarizer()\n",
        "\n",
        "        # ä¿æŒåŸå§‹æ¸¬è©¦æ•¸æ“š\n",
        "        self.sim_data = [\n",
        "            (\"äººå·¥æ™ºæ…§æ˜¯æœªä¾†çš„è¶¨å‹¢\", \"AIæŠ€è¡“å°‡ä¸»å°æœªä¾†çš„ç™¼å±•\"),\n",
        "            (\"ä»Šå¤©å¤©æ°£çœŸå¥½\", \"æ©Ÿå™¨å­¸ç¿’éœ€è¦å¤§é‡æ•¸æ“š\")\n",
        "        ]\n",
        "        self.clf_data = [\n",
        "            \"é€™å®¶é¤å»³çš„ç‰›è‚‰éºµçœŸçš„å¤ªå¥½åƒäº†ï¼Œæ¹¯é ­æ¿ƒéƒï¼Œéºµæ¢Qå½ˆï¼Œä¸‹æ¬¡ä¸€å®šå†ä¾†ï¼\",\n",
        "            \"æœ€æ–°çš„AIæŠ€è¡“çªç ´è®“äººé©šè‰·ï¼Œæ·±åº¦å­¸ç¿’æ¨¡å‹çš„è¡¨ç¾è¶Šä¾†è¶Šå¥½\",\n",
        "            \"é€™éƒ¨é›»å½±åŠ‡æƒ…ç©ºæ´ï¼Œæ¼”æŠ€ç³Ÿç³•ï¼Œå®Œå…¨æ˜¯æµªè²»æ™‚é–“\",\n",
        "            \"æ¯å¤©æ…¢è·‘5å…¬é‡Œï¼Œé…åˆé©ç•¶çš„é‡è¨“ï¼Œé«”èƒ½é€²æ­¥å¾ˆå¤š\"\n",
        "        ]\n",
        "        self.sum_article = \"\"\"äººå·¥æ™ºæ…§ (AI) çš„ç™¼å±•æ­£åœ¨æ·±åˆ»æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ã€‚å¾æ—©ä¸Šèµ·åºŠæ™‚çš„æ™ºæ…§é¬§é˜ï¼Œåˆ°é€šå‹¤æ™‚çš„è·¯ç·šè¦åŠƒï¼Œå†åˆ°å·¥ä½œä¸­çš„å„ç¨®è¼”åŠ©å·¥å…·ï¼ŒAIç„¡è™•ä¸åœ¨ã€‚\\n\\nåœ¨é†«ç™‚é ˜åŸŸï¼ŒAIå”åŠ©é†«ç”Ÿé€²è¡Œç–¾ç—…è¨ºæ–·ï¼Œæé«˜äº†è¨ºæ–·çš„æº–ç¢ºç‡å’Œæ•ˆç‡ã€‚é€éåˆ†æå¤§é‡çš„é†«ç™‚å½±åƒå’Œç—…æ­·è³‡æ–™ï¼ŒAIèƒ½å¤ ç™¼ç¾äººçœ¼å®¹æ˜“å¿½ç•¥çš„ç´°ç¯€ï¼Œç‚ºæ‚£è€…æä¾›æ›´å¥½çš„æ²»ç™‚æ–¹æ¡ˆã€‚\\n\\næ•™è‚²æ–¹é¢ï¼ŒAIå€‹äººåŒ–å­¸ç¿’ç³»çµ±èƒ½å¤ æ ¹æ“šæ¯å€‹å­¸ç”Ÿçš„å­¸ç¿’é€²åº¦å’Œç‰¹é»ï¼Œæä¾›å®¢è£½åŒ–çš„æ•™å­¸å…§å®¹ã€‚é€™ç¨®å› ææ–½æ•™çš„æ–¹å¼ï¼Œè®“å­¸ç¿’è®Šå¾—æ›´åŠ é«˜æ•ˆå’Œæœ‰è¶£ã€‚\\n\\nç„¶è€Œï¼ŒAIçš„å¿«é€Ÿç™¼å±•ä¹Ÿå¸¶ä¾†äº†ä¸€äº›æŒ‘æˆ°ã€‚é¦–å…ˆæ˜¯å°±æ¥­å•é¡Œï¼Œè¨±å¤šå‚³çµ±å·¥ä½œå¯èƒ½æœƒè¢«AIå–ä»£ã€‚å…¶æ¬¡æ˜¯éš±ç§å’Œå®‰å…¨å•é¡Œï¼ŒAIç³»çµ±éœ€è¦å¤§é‡æ•¸æ“šä¾†è¨“ç·´ï¼Œå¦‚ä½•ä¿è­·å€‹äººéš±ç§æˆç‚ºé‡è¦è­°é¡Œã€‚æœ€å¾Œæ˜¯å€«ç†å•é¡Œï¼ŒAIçš„æ±ºç­–éç¨‹å¾€å¾€ç¼ºä¹é€æ˜åº¦ï¼Œå¯èƒ½æœƒç”¢ç”Ÿåè¦‹æˆ–æ­§è¦–ã€‚\\n\\né¢å°é€™äº›æŒ‘æˆ°ï¼Œæˆ‘å€‘éœ€è¦åœ¨æ¨å‹•AIç™¼å±•çš„åŒæ™‚ï¼Œå»ºç«‹ç›¸æ‡‰çš„æ³•å¾‹æ³•è¦å’Œå€«ç†æº–å‰‡ã€‚åªæœ‰é€™æ¨£ï¼Œæ‰èƒ½ç¢ºä¿AIæŠ€è¡“çœŸæ­£ç‚ºäººé¡ç¦ç¥‰æœå‹™ï¼Œå‰µé€ ä¸€å€‹æ›´ç¾å¥½çš„æœªä¾†ã€‚\"\"\"\n",
        "\n",
        "        self.results_dir = \"results\"\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "        self.performance_metrics = {}\n",
        "\n",
        "    # ç•¥é plot_tfidf_similarityã€compare_similarityã€compare_classification ç­‰å‡½å¼çš„ç¨‹å¼ç¢¼ï¼Œ\n",
        "    # é€™äº›å‡½å¼å°‡æœƒæ­£ç¢ºèª¿ç”¨ Section 1 å’Œ Section 2 ä¸­å®šç¾©çš„å‡½å¼ã€‚\n",
        "\n",
        "    def plot_tfidf_similarity(self, documents):\n",
        "        print(\"\\n[ç”Ÿæˆ TF-IDF ç›¸ä¼¼åº¦çŸ©é™£åœ–...]\")\n",
        "        try:\n",
        "\n",
        "            # 1. å…ˆå°æ‰€æœ‰æ–‡ä»¶é€²è¡Œä¸­æ–‡æ–·è©ï¼Œä¸¦ç”¨ç©ºç™½é€£æ¥\n",
        "            # ä¾‹å¦‚ï¼š\"äººå·¥æ™ºæ…§...\" -> \"äººå·¥æ™ºæ…§ æ­£åœ¨ æ”¹è®Š ä¸–ç•Œ...\"\n",
        "            documents_cut = [\" \".join(jieba.lcut(doc)) for doc in documents]\n",
        "\n",
        "            # 2. ä½¿ç”¨é è¨­çš„ TfidfVectorizer (å®ƒæœƒä¾ç…§ç©ºç™½åˆ‡åˆ†)\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            matrix = vectorizer.fit_transform(documents_cut)\n",
        "\n",
        "\n",
        "            sim_matrix = cosine_similarity(matrix)\n",
        "            doc_labels = [f\"æ–‡ä»¶{i+1}\" for i in range(len(documents))]\n",
        "\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            # ä½¿ç”¨æ”¯æ´ä¸­æ–‡çš„å­—å‹ (my_font æ˜¯æ‚¨å‰é¢å®šç¾©å¥½çš„)\n",
        "            ax = sns.heatmap(sim_matrix, annot=True, cmap=\"YlGnBu\", fmt=\".4f\",\n",
        "                             xticklabels=doc_labels, yticklabels=doc_labels)\n",
        "\n",
        "            ax.set_xticklabels(doc_labels, fontproperties=my_font, rotation=0)\n",
        "            ax.set_yticklabels(doc_labels, fontproperties=my_font, rotation=0)\n",
        "\n",
        "            plt.title(\"TF-IDF ç›¸ä¼¼åº¦çŸ©é™£ \", fontproperties=my_font, fontsize=14)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            save_path = os.path.join(self.results_dir, \"tfidf_similarity_matrix.png\")\n",
        "            plt.savefig(save_path)\n",
        "            plt.close()\n",
        "            print(f\"âœ… åœ–ç‰‡å„²å­˜æˆåŠŸ : {save_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ç¹ªåœ–å¤±æ•—: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    def compare_similarity(self):\n",
        "        times_trad, times_ai = [], []\n",
        "        for t1, t2 in self.sim_data:\n",
        "            s = time.time()\n",
        "            self.trad_sim.get_similarity(t1, t2)\n",
        "            times_trad.append(time.time() - s)\n",
        "            s = time.time()\n",
        "            ai_similarity(t1, t2)\n",
        "            times_ai.append(time.time() - s)\n",
        "        self.performance_metrics['sim_time_trad'] = np.mean(times_trad)\n",
        "        self.performance_metrics['sim_time_ai'] = np.mean(times_ai)\n",
        "\n",
        "    def compare_classification(self):\n",
        "        times_trad, times_ai = [], []\n",
        "        correct_trad, correct_ai = 0, 0\n",
        "        expected_topics = [\"ç¾é£Ÿ\", \"ç§‘æŠ€\", \"é›»å½±\", \"é‹å‹•\"]\n",
        "\n",
        "        results = []\n",
        "        for i, text in enumerate(self.clf_data):\n",
        "            # Traditional\n",
        "            s = time.time()\n",
        "            res_trad = self.trad_clf.classify(text)\n",
        "            times_trad.append(time.time() - s)\n",
        "            if res_trad['topic'] == expected_topics[i]: correct_trad += 1\n",
        "\n",
        "            # AI\n",
        "            s = time.time()\n",
        "            res_ai = ai_classify(text)\n",
        "            times_ai.append(time.time() - s)\n",
        "            if expected_topics[i] in str(res_ai.get('topic', '')): correct_ai += 1\n",
        "\n",
        "            results.append({\n",
        "                \"text\": text,\n",
        "                \"trad\": res_trad,\n",
        "                \"ai\": res_ai\n",
        "            })\n",
        "\n",
        "        csv_path = os.path.join(self.results_dir, \"classification_results.csv\")\n",
        "        pd.DataFrame(results).to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "        print(f\"âœ… åˆ†é¡çµæœå·²å„²å­˜ (4ç­†è³‡æ–™): {csv_path}\")\n",
        "\n",
        "\n",
        "        self.performance_metrics['clf_time_trad'] = np.mean(times_trad)\n",
        "        self.performance_metrics['clf_time_ai'] = np.mean(times_ai)\n",
        "        self.performance_metrics['clf_acc_trad'] = (correct_trad / len(self.clf_data)) * 100\n",
        "        self.performance_metrics['clf_acc_ai'] = (correct_ai / len(self.clf_data)) * 100\n",
        "\n",
        "    def compare_summarization(self):\n",
        "        # é€™è£¡ç¾åœ¨æœƒå‘¼å« Section 1 ä¸­å®šç¾©çš„çœŸå¯¦ API å‡½å¼ï¼Œè€Œéæ¨¡æ“¬å‡½å¼\n",
        "        s = time.time()\n",
        "        trad_res, _ = self.trad_sum.summarize(self.sum_article)\n",
        "        time_trad = time.time() - s\n",
        "        s = time.time()\n",
        "        ai_res = ai_summarize(self.sum_article)\n",
        "        time_ai = time.time() - s\n",
        "\n",
        "        with open(os.path.join(self.results_dir, \"summarization_comparison.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Traditional:\\n{trad_res}\\n\\nAI:\\n{ai_res}\")\n",
        "\n",
        "        self.performance_metrics['sum_time_trad'] = time_trad\n",
        "        self.performance_metrics['sum_time_ai'] = time_ai\n",
        "\n",
        "    def generate_comparison_table(self):\n",
        "        print(\"\\n[C-1 é‡åŒ–æ¯”è¼ƒè¡¨æ ¼]\")\n",
        "\n",
        "        data = [\n",
        "            [\"ç›¸ä¼¼åº¦è¨ˆç®—\", \"\", \"\", \"\"],\n",
        "            [\"\", \"æº–ç¢ºç‡\", \"ä½ (åƒ…å­—é¢)\", \"é«˜ (å«èªæ„)\"],\n",
        "            [\"\", \"è™•ç†æ™‚é–“\", f\"{self.performance_metrics.get('sim_time_trad', 0):.4f}ç§’\", f\"{self.performance_metrics.get('sim_time_ai', 0):.4f}ç§’\"],\n",
        "            [\"\", \"æˆæœ¬\", \"$0\", \"Tokenè¨ˆè²»\"],\n",
        "            [\"æ–‡æœ¬åˆ†é¡\", \"\", \"\", \"\"],\n",
        "            [\"\", \"æº–ç¢ºç‡\", f\"{self.performance_metrics.get('clf_acc_trad', 0):.0f}%\", f\"{self.performance_metrics.get('clf_acc_ai', 0):.0f}%\"],\n",
        "            [\"\", \"è™•ç†æ™‚é–“\", f\"{self.performance_metrics.get('clf_time_trad', 0):.4f}ç§’\", f\"{self.performance_metrics.get('clf_time_ai', 0):.4f}ç§’\"],\n",
        "            [\"\", \"æ”¯æ´é¡åˆ¥\", \"æœ‰é™\", \"ç„¡é™\"],\n",
        "            [\"è‡ªå‹•æ‘˜è¦\", \"\", \"\", \"\"],\n",
        "            [\"\", \"è³‡è¨Šä¿ç•™åº¦\", \"ä¸­ (æŠ½å–)\", \"é«˜ (ç”Ÿæˆ)\"],\n",
        "            [\"\", \"èªå¥é€šé †åº¦\", \"ä½ (æ‹¼æ¥)\", \"é«˜ (è‡ªç„¶)\"],\n",
        "            [\"\", \"é•·åº¦æ§åˆ¶\", \"å›°é›£\", \"å®¹æ˜“\"]\n",
        "        ]\n",
        "\n",
        "        columns = [\"è©•ä¼°é¢å‘\", \"è©•ä¼°æŒ‡æ¨™\", \"TF-IDF (å‚³çµ±)\", \"GPT-4o (AI)\"]\n",
        "        df = pd.DataFrame(data, columns=columns)\n",
        "        # é¡¯ç¤º DataFrame\n",
        "        display(df)\n",
        "        #df.to_csv(os.path.join(self.results_dir, \"quantitative_comparison.csv\"), index=False, encoding='utf-8-sig')\n",
        "\n",
        "    def save_metrics(self):\n",
        "        with open(os.path.join(self.results_dir, \"performance_metrics.json\"), \"w\") as f:\n",
        "            json.dump(self.performance_metrics, f, indent=4)\n",
        "\n",
        "    def run_full_report(self):\n",
        "        print(\"=\"*60)\n",
        "        print(\"ã€NLP æŠ€è¡“å°æ¯”åˆ†æå ±å‘Šã€‘\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        self.compare_similarity()\n",
        "        self.compare_classification()\n",
        "        self.compare_summarization()\n",
        "        self.plot_tfidf_similarity(documents_for_A1)\n",
        "        self.generate_comparison_table()\n",
        "        self.save_metrics()\n",
        "\n",
        "        print(\"\\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼\")\n",
        "        print(f\"çµæœæª”æ¡ˆä½ç½®: {self.results_dir}/\")\n",
        "\n",
        "\n",
        "# ==================== 4. åŸ·è¡Œç¨‹å¼ ====================\n",
        "analyzer = ComparisonAnalysis_With_Saving()\n",
        "analyzer.run_full_report()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}