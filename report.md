# C-1: 量化比較 

| 評估指標 | TF-IDF (傳統) | GPT-4o (AI) |
| :--- | :--- | :--- |
| **相似度計算** | | |
| 準確率 | 低 (僅字面) | 高 (含語意) |
| 處理時間 | 0.0055 秒 | 0.6062 秒 |
| 成本 | $0 | Token 計費 |
| **文本分類** | | |
| 準確率 | 50% | 100% |
| 處理時間 | 0.0003 秒 | 0.5522 秒 |
| 支援類別數 | 有限 | 無限 |
| **自動摘要** | | |
| 資訊保留度 | 中 (抽取) | 高 (生成) |
| 語句通順度 | 低 (拼接) | 高 (自然) |
| 長度控制 | 困難 | 容易 |

<br>
<br>
<br>

# C-2: 質性分析
## 1. 方法特性比較

### 傳統方法的優勢與限制

優勢：運算速度極快，幾乎不需要昂貴的硬體資源；邏輯透明且具可解釋性（白箱模型），我們可以清楚知道為什麼某個關鍵字觸發了分類；開發與維護成本低（無需 Token 費用）。

限制：無法理解語意是最大致命傷。正如本次實作的 TF-IDF 矩陣所示，雖然有運用斷詞，但它仍然依賴「字面上的重疊」。如果兩篇文章用詞不同（例如一篇用「計算機」，另一篇用「電腦」），即便指涉相同概念，傳統方法計算出的相似度仍會過低，無法像 AI 一樣捕捉到概念上的關聯。

適用場景：關鍵字搜尋、簡單的指令過濾（如 Spam filter）、對延遲要求極低且算力受限的嵌入式系統。

### AI 方法的優勢與限制

優勢：具備強大的語意理解能力與上下文推理能力。能準確判斷「天氣很好」與「運動」的關聯，或將「人工智慧」與「深度學習」視為高度相關；在生成摘要時能重組語句，產出流暢且自然的文本。

限制：成本較高（依 Token 計費）；推理速度較慢，存在 API 延遲；具有「黑箱」特性，偶爾會產生幻覺 (Hallucination) 或不可預測的輸出。

適用場景：複雜的意圖識別、自動摘要生成、創意寫作、客服對話機器人、情感分析等需要深度理解的任務。

## 2. 實作心得

### 實作過程中遇到的困難

最深刻的體會在於「中文斷詞（Tokenization）」對傳統方法的決定性影響。 起初實作 TF-IDF 時，因未引入 Jieba 等專業斷詞庫，導致程式將整句話視為一個詞，相似度計算失效（全為 0）。在加入 Jieba 斷詞並修正後，雖然成功算出了相似度數值，但也讓我意識到傳統 NLP 方法對「前處理工程」的高度依賴——若斷詞不精準或遭遇新詞（Out-of-Vocabulary），效果就會大打折扣。

### 對兩種方法的理解和感受

傳統方法像是一個「精確的比對機器」，它嚴格遵守指令，雖然在修正斷詞後能比對出相同詞彙，但本質上仍是不懂變通的，一字之差往往就影響計算結果。
AI 方法則像是一個「博學的助理」，它能讀懂字裡行間的意思，即便用詞不同也能抓到核心概念。從分類結果來看，AI 能給出更細膩的信心分數與正確的主題判斷。

### 未來的學習方向

針對傳統方法的不足，未來應學習 Word Embeddings (詞嵌入) 技術（如 Word2Vec, BERT 嵌入），這能解決 TF-IDF 無法捕捉語義的問題，同時保留向量計算的高效性。此外，也需要深入鑽研 Prompt Engineering，以更精準地控制大型語言模型的輸出品質。

## 3. 應用建議

### 什麼情況下該用傳統方法？

當任務定義非常明確且範圍封閉（例如：檢查身分證字號格式、特定指令觸發）時。

當資料量極大且對隱私與即時性有嚴格要求，且無法連網的環境。

預算極其有限，無法負擔持續性的 API 呼叫成本時。

### 什麼情況下該用 AI？

處理非結構化資料（如自由文本、對話記錄）時。

需要生成內容（撰寫郵件、摘要文章）或進行複雜推理（情感分析、跨語言翻譯）時。

當開發時間緊迫，需要快速驗證產品概念（MVP）時，AI 能大幅縮短開發週期。

### 如何結合兩者的優點？

採用 「混合式架構 (Hybrid Approach)」：

初篩 (Filter)：先利用傳統關鍵字或正則表達式快速過濾掉 80% 的無關數據或簡單請求（低成本、高速度）。

精判 (Refine)：將剩餘 20% 模糊或複雜的案例，傳送給 AI 模型進行深度分析（高品質）。

例如在客服系統中，簡單的「查詢餘額」由規則引擎直接回覆，而複雜的「客訴」則轉交由 AI 分析情緒並生成安撫回應。

